{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average age for Parch: \n",
      " {0: 32.10982658959538, 1: 24.422, 2: 17.216911764705884, 3: 33.2, 4: 44.5, 5: 39.2, 6: 43.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# read the data from csv file\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# drop these because they shouldn't matter (name) or have too many missing values (cabin)\n",
    "df.drop(axis=1, labels=['PassengerId', 'Name', 'Ticket', 'Cabin'], inplace=True)\n",
    "\n",
    "# count how many missing values per column\n",
    "# print(df.isna().sum())\n",
    "\n",
    "# drop the two empty rows with embarked missing\n",
    "df.dropna(axis=0, subset=['Embarked'], inplace=True)\n",
    "\n",
    "# There are 177 missing values for age. Guess age based on Parch number (number of parents/child on board).\n",
    "# Age should be somewhat related to number of parents and children aboard.\n",
    "# Logically, if someone's a child/teen, you'd expect the parents to be aboard. The older someone is, the more children you'd expect them to have.\n",
    "avg_age_by_parch = df.groupby(['Parch'])['Age'].mean().to_dict()\n",
    "print(f'average age for Parch: \\n {avg_age_by_parch}')\n",
    "\n",
    "# Fill in missing age values based on Parch.\n",
    "def fill_missing_age(row):\n",
    "    if math.isnan(row.Age):\n",
    "        parch = row.Parch\n",
    "        row.Age = avg_age_by_parch[parch]\n",
    "    return row\n",
    "\n",
    "df = df.transform(lambda row: fill_missing_age(row), axis=1)\n",
    "\n",
    "# print(df.isna().sum())\n",
    "\n",
    "# Transform categorical variables with one-hot encoding\n",
    "df = pd.get_dummies(data=df, columns=['Sex', 'Pclass', 'Embarked'])\n",
    "\n",
    "X = df.drop(axis=1, labels=['Survived'])\n",
    "y = df['Survived'].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result {'mean_fit_time': array([0.37842979, 0.37802057, 0.29810033, 0.3804461 , 0.42729115,\n",
      "       0.34291682, 0.37688208, 0.44704566, 0.36311278, 0.37501636,\n",
      "       0.44639392, 0.38277125, 0.38315363, 0.45178289, 0.37188053]), 'std_fit_time': array([0.01436441, 0.00592953, 0.00508389, 0.00512103, 0.01041294,\n",
      "       0.00675269, 0.01154707, 0.01108102, 0.00791582, 0.00821101,\n",
      "       0.00700102, 0.0071994 , 0.00862944, 0.01053377, 0.02006084]), 'mean_score_time': array([0.00145063, 0.00143905, 0.00141697, 0.00145144, 0.00148664,\n",
      "       0.00156021, 0.00148935, 0.00145383, 0.00151238, 0.00147824,\n",
      "       0.00146799, 0.00153875, 0.00147982, 0.0015039 , 0.0014164 ]), 'std_score_time': array([3.64774504e-05, 1.39489336e-05, 4.51357037e-05, 3.78908260e-05,\n",
      "       6.29377363e-05, 1.61990713e-04, 6.97655947e-05, 2.41627085e-05,\n",
      "       6.52066053e-05, 6.69479030e-05, 3.30883073e-05, 1.01988880e-04,\n",
      "       1.09852767e-05, 9.15606068e-05, 6.01847835e-05]), 'param_C': masked_array(data=[0.05, 0.05, 0.05, 0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 1, 1,\n",
      "                   1, 5, 5, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_penalty': masked_array(data=['none', 'l1', 'l2', 'none', 'l1', 'l2', 'none', 'l1',\n",
      "                   'l2', 'none', 'l1', 'l2', 'none', 'l1', 'l2'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.05, 'penalty': 'none'}, {'C': 0.05, 'penalty': 'l1'}, {'C': 0.05, 'penalty': 'l2'}, {'C': 0.1, 'penalty': 'none'}, {'C': 0.1, 'penalty': 'l1'}, {'C': 0.1, 'penalty': 'l2'}, {'C': 0.5, 'penalty': 'none'}, {'C': 0.5, 'penalty': 'l1'}, {'C': 0.5, 'penalty': 'l2'}, {'C': 1, 'penalty': 'none'}, {'C': 1, 'penalty': 'l1'}, {'C': 1, 'penalty': 'l2'}, {'C': 5, 'penalty': 'none'}, {'C': 5, 'penalty': 'l1'}, {'C': 5, 'penalty': 'l2'}], 'split0_test_score': array([0.80898876, 0.73033708, 0.75280899, 0.80898876, 0.80337079,\n",
      "       0.79775281, 0.80898876, 0.81460674, 0.80898876, 0.80898876,\n",
      "       0.80898876, 0.80898876, 0.80898876, 0.80898876, 0.80898876]), 'split1_test_score': array([0.79213483, 0.81460674, 0.80337079, 0.79213483, 0.80337079,\n",
      "       0.80337079, 0.79213483, 0.79213483, 0.79213483, 0.79213483,\n",
      "       0.79213483, 0.79213483, 0.79213483, 0.79213483, 0.79213483]), 'split2_test_score': array([0.78651685, 0.7752809 , 0.82022472, 0.78651685, 0.7752809 ,\n",
      "       0.79213483, 0.78651685, 0.7752809 , 0.78651685, 0.78651685,\n",
      "       0.78089888, 0.78651685, 0.78651685, 0.78089888, 0.78651685]), 'split3_test_score': array([0.76404494, 0.75842697, 0.7752809 , 0.76404494, 0.76966292,\n",
      "       0.76404494, 0.76404494, 0.76404494, 0.76404494, 0.76404494,\n",
      "       0.76404494, 0.76404494, 0.76404494, 0.76404494, 0.76404494]), 'split4_test_score': array([0.81355932, 0.8079096 , 0.82485876, 0.81355932, 0.8079096 ,\n",
      "       0.82485876, 0.81355932, 0.81355932, 0.81355932, 0.81355932,\n",
      "       0.81355932, 0.81355932, 0.81355932, 0.81355932, 0.81355932]), 'mean_test_score': array([0.79304894, 0.77731226, 0.79530883, 0.79304894, 0.791919  ,\n",
      "       0.79643243, 0.79304894, 0.79192535, 0.79304894, 0.79304894,\n",
      "       0.79192535, 0.79304894, 0.79304894, 0.79192535, 0.79304894]), 'std_test_score': array([0.01766063, 0.03128746, 0.02744576, 0.01766063, 0.01606329,\n",
      "       0.01962325, 0.01766063, 0.02018352, 0.01766063, 0.01766063,\n",
      "       0.01821062, 0.01766063, 0.01766063, 0.01821062, 0.01766063]), 'rank_test_score': array([ 3, 15,  2,  3, 14,  1,  3, 11,  3,  3, 11,  3,  3, 11,  3],\n",
      "      dtype=int32)}\n",
      "best score 0.7964324255697328\n",
      "best params {'C': 0.1, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = LogisticRegression(solver='saga', max_iter=5000, random_state=0)\n",
    "\n",
    "param_grid = { 'penalty': ['none', 'l1', 'l2'], 'C': [0.05, 0.1, 0.5, 1, 5] }\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "result = grid_search.cv_results_\n",
    "estimator = grid_search.best_estimator_\n",
    "score = grid_search.best_score_\n",
    "params = grid_search.best_params_\n",
    "\n",
    "print('result', result)\n",
    "print('best score', score)\n",
    "print('best params', params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>none</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>0.793049</td>\n",
       "      <td>0.777312</td>\n",
       "      <td>0.793049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.793049</td>\n",
       "      <td>0.791919</td>\n",
       "      <td>0.796432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.793049</td>\n",
       "      <td>0.791925</td>\n",
       "      <td>0.793049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.793049</td>\n",
       "      <td>0.791925</td>\n",
       "      <td>0.793049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.793049</td>\n",
       "      <td>0.791925</td>\n",
       "      <td>0.793049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          none        L1        L2\n",
       "0.05  0.793049  0.777312  0.793049\n",
       "0.1   0.793049  0.791919  0.796432\n",
       "0.5   0.793049  0.791925  0.793049\n",
       "1     0.793049  0.791925  0.793049\n",
       "5     0.793049  0.791925  0.793049"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'0.05': [0.79304894, 0.77731226, 0.79304894], '0.1': [0.79304894, 0.791919, 0.79643243], '0.5': [0.79304894,0.79192535, 0.79304894], '1': [0.79304894, 0.79192535, 0.79304894], '5': [0.79304894, 0.79192535, 0.79304894]}\n",
    "\n",
    "pd.DataFrame.from_dict(data, orient='index', columns=['none', 'L1', 'L2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tuned</th>\n",
       "      <th>not tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.816479</td>\n",
       "      <td>0.812734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.784091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1 score</th>\n",
       "      <td>0.735135</td>\n",
       "      <td>0.734043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tuned  not tuned\n",
       "accuracy   0.816479   0.812734\n",
       "precision  0.800000   0.784091\n",
       "recall     0.680000   0.690000\n",
       "f1 score   0.735135   0.734043"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "tuned = LogisticRegression(solver='saga', penalty='l2', C=0.1, max_iter=5000, random_state=2)\n",
    "not_tuned = LogisticRegression(solver='saga', penalty='none', max_iter=5000, random_state=2)\n",
    "\n",
    "tuned.fit(X_train, y_train)\n",
    "not_tuned.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tuned = tuned.predict(X_test)\n",
    "y_pred_not_tuned = not_tuned.predict(X_test)\n",
    "\n",
    "data = {\n",
    "    'accuracy': [accuracy_score(y_test, y_pred_tuned), accuracy_score(y_test, y_pred_not_tuned)],\n",
    "    'precision': [precision_score(y_test, y_pred_tuned), precision_score(y_test, y_pred_not_tuned)],\n",
    "    'recall': [recall_score(y_test, y_pred_tuned), recall_score(y_test, y_pred_not_tuned)],\n",
    "    'f1 score': [f1_score(y_test, y_pred_tuned), f1_score(y_test, y_pred_not_tuned)]\n",
    "}\n",
    "\n",
    "pd.DataFrame.from_dict(data, orient='index', columns=['tuned', 'not tuned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/yilingchen/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RamdomSearchCV took 21.51 seconds for 10 candidate parameter settings.\n",
      "result {'mean_fit_time': array([0.39062195, 0.38298984, 0.53506203, 0.47354364, 0.38138165,\n",
      "       0.45008602, 0.46061711, 0.36605401, 0.37935429, 0.37606468]), 'std_fit_time': array([0.00981839, 0.01590599, 0.14115094, 0.0086145 , 0.01035077,\n",
      "       0.01471578, 0.01987717, 0.01590375, 0.00483349, 0.01015617]), 'mean_score_time': array([0.00155358, 0.00152655, 0.00174222, 0.00155902, 0.00153136,\n",
      "       0.00144339, 0.00146179, 0.00141397, 0.00146575, 0.00152678]), 'std_score_time': array([1.14754842e-04, 1.42222420e-04, 2.74156884e-04, 1.73862701e-04,\n",
      "       1.11084842e-04, 3.85575256e-05, 4.52272943e-05, 6.52874529e-05,\n",
      "       4.54739675e-05, 8.13840205e-05]), 'param_C': masked_array(data=[2.7440675196366238, 4.2213287429050865,\n",
      "                   3.1178184839298617, 2.1879360563134624,\n",
      "                   0.2835648865872159, 1.9172075941288886,\n",
      "                   4.060843643877466, 2.8402228054696614,\n",
      "                   4.180393817686888, 0.43564649850770354],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_penalty': masked_array(data=['l2', 'l2', 'l1', 'l1', 'none', 'l1', 'l1', 'l2',\n",
      "                   'none', 'none'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 2.7440675196366238, 'penalty': 'l2'}, {'C': 4.2213287429050865, 'penalty': 'l2'}, {'C': 3.1178184839298617, 'penalty': 'l1'}, {'C': 2.1879360563134624, 'penalty': 'l1'}, {'C': 0.2835648865872159, 'penalty': 'none'}, {'C': 1.9172075941288886, 'penalty': 'l1'}, {'C': 4.060843643877466, 'penalty': 'l1'}, {'C': 2.8402228054696614, 'penalty': 'l2'}, {'C': 4.180393817686888, 'penalty': 'none'}, {'C': 0.43564649850770354, 'penalty': 'none'}], 'split0_test_score': array([0.80898876, 0.80898876, 0.80898876, 0.80898876, 0.80898876,\n",
      "       0.80898876, 0.80898876, 0.80898876, 0.80898876, 0.80898876]), 'split1_test_score': array([0.79213483, 0.79213483, 0.79213483, 0.79213483, 0.79213483,\n",
      "       0.79213483, 0.79213483, 0.79213483, 0.79213483, 0.79213483]), 'split2_test_score': array([0.78651685, 0.78651685, 0.78089888, 0.78089888, 0.78651685,\n",
      "       0.78089888, 0.78089888, 0.78651685, 0.78651685, 0.78651685]), 'split3_test_score': array([0.76404494, 0.76404494, 0.76404494, 0.76404494, 0.76404494,\n",
      "       0.76404494, 0.76404494, 0.76404494, 0.76404494, 0.76404494]), 'split4_test_score': array([0.81355932, 0.81355932, 0.81355932, 0.81355932, 0.81355932,\n",
      "       0.81355932, 0.81355932, 0.81355932, 0.81355932, 0.81355932]), 'mean_test_score': array([0.79304894, 0.79304894, 0.79192535, 0.79192535, 0.79304894,\n",
      "       0.79192535, 0.79192535, 0.79304894, 0.79304894, 0.79304894]), 'std_test_score': array([0.01766063, 0.01766063, 0.01821062, 0.01821062, 0.01766063,\n",
      "       0.01821062, 0.01821062, 0.01766063, 0.01766063, 0.01766063]), 'rank_test_score': array([1, 1, 7, 7, 1, 7, 7, 1, 1, 1], dtype=int32)}\n",
      "best score 0.7930489430584651\n",
      "best params {'C': 2.7440675196366238, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "logistic = LogisticRegression(solver='saga', max_iter=5000, random_state=0)\n",
    "\n",
    "distributions = dict(C=uniform(loc=0, scale=5), penalty=['none', 'l2', 'l1'])\n",
    "\n",
    "random_search = RandomizedSearchCV(logistic, distributions, random_state=0)\n",
    "\n",
    "start = time()\n",
    "\n",
    "random_search.fit(X, y)\n",
    "\n",
    "print(\"RamdomSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(random_search.cv_results_['params'])))\n",
    "\n",
    "result = random_search.cv_results_\n",
    "estimator = random_search.best_estimator_\n",
    "score = random_search.best_score_\n",
    "params = random_search.best_params_\n",
    "\n",
    "print('result', result)\n",
    "print('best score', score)\n",
    "print('best params', params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66930743 0.71540024 0.69619755 0.67260204 0.66823462 0.71435917\n",
      " 0.66930743 0.71540024 0.69619755 0.70293912 0.66485114 0.6928839\n",
      " 0.66930743 0.71540024 0.69619755 0.70630991 0.62105631 0.58608519\n",
      " 0.66930743 0.71427665 0.69619755 0.64788294 0.66586047 0.55462452\n",
      " 0.66930743 0.71764743 0.66923126 0.52204025 0.59619755 0.56586047\n",
      " 0.66706024 0.6884276  0.65237732 0.59732115 0.56248968 0.57035485]\n",
      "{1e-05: {'x': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1], 'y': [0.6693074335047292, 0.7154002412238938, 0.6961975496730781, 0.6726020440551006, 0.6682346219767663, 0.7143591696819653]}, 0.0001: {'x': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1], 'y': [0.6693074335047292, 0.7154002412238938, 0.6961975496730781, 0.702939122706786, 0.6648511394654987, 0.6928838951310861]}, 0.001: {'x': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1], 'y': [0.6693074335047292, 0.7154002412238938, 0.6961975496730781, 0.7063099092236398, 0.621056306735225, 0.5860851901225164]}, 0.01: {'x': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1], 'y': [0.6693074335047292, 0.7142766457182759, 0.6961975496730781, 0.6478829429315051, 0.6658604710213928, 0.554624515965213]}, 0.1: {'x': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1], 'y': [0.6693074335047292, 0.7176474322351297, 0.6692312575382466, 0.5220402463022916, 0.5961975496730781, 0.5658604710213927]}, 1: {'x': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1], 'y': [0.6670602424934933, 0.6884276010918556, 0.652377324953977, 0.5973211451786961, 0.5624896845045388, 0.5703548530438647]}}\n",
      "best score 0.7176474322351297\n",
      "best params {'alpha': 0.1, 'eta0': 0.0001, 'learning_rate': 'constant'}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sgd = SGDClassifier(loss=\"log\", penalty=\"l2\", max_iter=50000, random_state=100)\n",
    "\n",
    "param_grid = {\n",
    "  'eta0': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1],\n",
    "  'learning_rate': ['constant'],\n",
    "  'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(sgd, param_grid=param_grid)\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "result = grid_search.cv_results_\n",
    "estimator = grid_search.best_estimator_\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "mean_scores = result['mean_test_score']\n",
    "\n",
    "scores_combo = {} # {[alpha_value]: { x: [eta0 values], y: [scores]}}\n",
    "\n",
    "for idx, param in enumerate(result['params']):\n",
    "    alpha = param['alpha']\n",
    "    eta0 = param['eta0']\n",
    "    score = mean_scores[idx]\n",
    "    if scores_combo.get(alpha):\n",
    "        scores_combo[alpha]['x'].append(eta0)\n",
    "        scores_combo[alpha]['y'].append(score)\n",
    "    else:\n",
    "        scores_combo[alpha] = {'x': [eta0], 'y': [score]}\n",
    "    \n",
    "\n",
    "print(mean_scores)\n",
    "print(scores_combo)\n",
    "print('best score', best_score)\n",
    "print('best params', best_params)\n",
    "\n",
    "for key in scores_combo:\n",
    "    if key == 0.1 or key == 0.01:\n",
    "        values = scores_combo[key]\n",
    "        label = f'alpha={key}'\n",
    "        plt.scatter(values['x'], values['y'], label=label)\n",
    "        \n",
    "plt.title('Learning rate vs. accuracy')\n",
    "plt.xlabel('Learning rate (eta0)')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
